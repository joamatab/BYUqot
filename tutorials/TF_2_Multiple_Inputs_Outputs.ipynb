{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X + Y Regression with Complex Numbers\n",
    "\n",
    "This is another regression example using complex data, and modeling the surface X + Y = Z, where X and Y are both complex numbers.\n",
    "\n",
    "Note this is largely based on the previous example, so only new concepts will be covered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "linear = lambda x: x\n",
    "\n",
    "def layer(act_func, input_val, input_num, output_num):\n",
    "    W = tf.Variable(tf.random_normal([input_num, output_num], stddev=0.03), dtype=tf.float32)\n",
    "    b = tf.Variable(tf.random_normal([output_num], stddev=0.03), dtype=tf.float32)\n",
    "    layer = act_func(tf.matmul(input_val,W) + b)\n",
    "    return layer\n",
    "\n",
    "epochs = 15000\n",
    "learning_rate = 0.001\n",
    "num_points = 50\n",
    "num_nodes = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice here, our input placeholder has 4 columns instead of the 1 we used before. This is to accommodate both real and imaginary parts of both X and Y.\n",
    "\n",
    "Right after the data is created and shuffled, then \"meshed\" to create a grid of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tf = tf.placeholder(tf.float32, [None,4])\n",
    "\n",
    "x_data = np.linspace(0, 20, num_points) + np.linspace(-10, 0, num_points)\n",
    "y_data = np.linspace(-30, 10, num_points) + np.linspace(20, 30, num_points)\n",
    "np.random.shuffle(x_data), np.random.shuffle(y_data)\n",
    "x_data, y_data = np.meshgrid(x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the data is reshaped to be shaped like the input_tf placeholder, and then stuck all together. Z is created shortly after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_data.reshape(-1,1)\n",
    "y_train = y_data.reshape(-1,1)\n",
    "input_data = np.hstack((x_train.real, x_train.imag, y_train.real, y_train.imag))\n",
    "\n",
    "z = tf.complex(input_tf[:,0:1], input_tf[:,1:2]) + tf.complex(input_tf[:,2:3], input_tf[:,3:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we have our first layer created with 4 inputs and 2 ouputs in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "dicts={}\n",
    "layers += [layer(tf.nn.leaky_relu, input_tf, 4, num_nodes)]\n",
    "for i in range(3):\n",
    "    dicts[i] = layer(tf.nn.leaky_relu, layers[-1], num_nodes, num_nodes)\n",
    "    layers += [dicts[i]]\n",
    "\n",
    "output = layer(linear, layers[-1], num_nodes, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice our loss functions this time are a little bit different. We'll take the loss of both the real parts of X and Y compared to the real part of the output, and the same for the imaginary parts. Then we simply sum them together for our total loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_real = tf.losses.mean_squared_error(tf.real(z), output[:,0:1])\n",
    "loss_imag = tf.losses.mean_squared_error(tf.imag(z), output[:,1:2])\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_imag+loss_real)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(epochs+1):\n",
    "        predict, _, curr_real, curr_imag = sess.run([output, train, loss_real, loss_imag], feed_dict={input_tf: input_data})\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Epoch: %s \\t Loss: %s\" % (i, curr_real+curr_imag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
